{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ9Z/E8tKMNLvjR0kjb16S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manglesh001/DL-assigment1/blob/main/DL_Ass1_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rLRUvo50IogF"
      },
      "outputs": [],
      "source": [
        "#import all necessary files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "gUXKOGA-JKbM",
        "outputId": "55c21da8-1cb7-499e-c9af-3c89f979a158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "Lb7q3rnTJLEW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the 28x28 images into 784-dimensional vectors\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "m4yGKEQBJLGy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test = encoder.transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "W4hdatkuJLJC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROlxIgGULFJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax  activation function ouput layer\n",
        "def softmax(self, x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "#Sigmoid activation function hidden layer\n",
        "def sigmoid(self, x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(self, x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "t6veP94YLIN6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Feedforward Neural Network (FFNN) Class\n",
        "class FFNN:\n",
        "    def __init__(self, layer_sizes):\n",
        "\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.01)\n",
        "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
        "\n",
        "    def relu(self, x):\n",
        "\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        self.activations = [x]  # Store activations for each layer\n",
        "        self.z_values = []      # Store pre-activation values for each layer\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
        "            self.z_values.append(z)\n",
        "\n",
        "            if i == len(self.weights) - 1:\n",
        "                # Output layer uses softmax\n",
        "                activation = self.softmax(z)\n",
        "            else:\n",
        "                # Hidden layers use ReLU\n",
        "                activation = self.relu(z)\n",
        "\n",
        "            self.activations.append(activation)\n",
        "\n",
        "        # Return the output probabilities\n",
        "        return self.activations[-1]\n",
        "\n",
        "    def predict_probabilities(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "xhk3ZZPKKlDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the network architecture\n",
        "layer_sizes = [784, 128, 64, 10]\n",
        "ffnn = FFNN(layer_sizes)"
      ],
      "metadata": {
        "id": "5l5qeAhlKnAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for the first 10 test images\n",
        "probabilities = ffnn.predict_probabilities(x_test[:10])\n",
        "print(\"Predicted Probabilities:\\n\", probabilities)"
      ],
      "metadata": {
        "id": "1zPTUBxCKAz5",
        "outputId": "2d58fe29-9116-4d55-fcc7-e6688167be55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities:\n",
            " [[0.10003018 0.09998407 0.09999149 0.1000355  0.09997448 0.10006295\n",
            "  0.09993764 0.10006806 0.1000014  0.09991423]\n",
            " [0.10002653 0.09993444 0.09997626 0.10005089 0.09992371 0.10020026\n",
            "  0.09987994 0.10013978 0.0999577  0.0999105 ]\n",
            " [0.1000114  0.09994278 0.100069   0.10003819 0.10003299 0.10008015\n",
            "  0.09990476 0.10008338 0.09998326 0.09985411]\n",
            " [0.10000958 0.09996585 0.10004972 0.10002507 0.10002765 0.10006126\n",
            "  0.09992205 0.10005027 0.09996352 0.09992504]\n",
            " [0.10003213 0.09994351 0.09995575 0.10004237 0.09996597 0.10008334\n",
            "  0.09993331 0.10008858 0.10002329 0.09993175]\n",
            " [0.10002274 0.09996513 0.10002825 0.10001148 0.09999534 0.10005498\n",
            "  0.09995279 0.10004891 0.09999773 0.09992264]\n",
            " [0.10000046 0.09999039 0.10000761 0.09998748 0.09997854 0.10005455\n",
            "  0.09997892 0.10002599 0.09999033 0.09998574]\n",
            " [0.10001088 0.09996042 0.09999407 0.10001897 0.09996057 0.10015371\n",
            "  0.09992837 0.1000622  0.09997219 0.09993862]\n",
            " [0.10001829 0.09999383 0.10000609 0.10001161 0.10000227 0.09999428\n",
            "  0.09997337 0.10002752 0.0999789  0.09999385]\n",
            " [0.10004238 0.09997086 0.09998817 0.10004532 0.09998439 0.10001277\n",
            "  0.09993956 0.10006832 0.09999735 0.09995088]]\n"
          ]
        }
      ]
    }
  ]
}