{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsGJkUDjhMdmHm48yg4KEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manglesh001/DL-assigment1/blob/main/DL_ASS1_Q7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import wandb\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "metadata": {
        "id": "o-Qq1m6Oc0Pe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
        "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test_original = y_test  # Keep original labels for confusion matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgTe-478c0SP",
        "outputId": "e33430d2-010b-4508-af1f-435d6f8c2607"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions and derivatives\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "qjJr87soc0Ug"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight Initialization\n",
        "def initialize_weights(layers, method=\"xavier\"):\n",
        "    weights = []\n",
        "    biases = []\n",
        "    for i in range(len(layers) - 1):\n",
        "        if method == \"xavier\":\n",
        "            weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(1 / layers[i]))\n",
        "        else:  # random\n",
        "            weights.append(np.random.randn(layers[i], layers[i+1]) * 0.01)\n",
        "        biases.append(np.zeros((1, layers[i+1])))\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "HV82DNvyc0Wy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Propagation\n",
        "def forward_propagation(X, weights, biases, activation):\n",
        "    activations = [X]\n",
        "    for i in range(len(weights)):\n",
        "        z = np.dot(activations[-1], weights[i]) + biases[i]\n",
        "        if activation[i] == \"sigmoid\":\n",
        "            activations.append(sigmoid(z))\n",
        "    return activations"
      ],
      "metadata": {
        "id": "yonN1PBxc0Zm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagation\n",
        "def backpropagation(y, activations, weights):\n",
        "    gradients_w = [None] * len(weights)\n",
        "    gradients_b = [None] * len(weights)\n",
        "    error = activations[-1] - y\n",
        "\n",
        "    for i in reversed(range(len(weights))):\n",
        "        delta = error * sigmoid_derivative(activations[i+1])\n",
        "        gradients_w[i] = np.dot(activations[i].T, delta)\n",
        "        gradients_b[i] = np.sum(delta, axis=0, keepdims=True)\n",
        "        error = np.dot(delta, weights[i].T)\n",
        "\n",
        "    return gradients_w, gradients_b"
      ],
      "metadata": {
        "id": "aXoa5fdec0cC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSprop Optimizer\n",
        "def rmsprop(weights, biases, gradients_w, gradients_b, lr, cache_w, cache_b, beta=0.99, epsilon=1e-8):\n",
        "    for i in range(len(weights)):\n",
        "        cache_w[i] = beta * cache_w[i] + (1 - beta) * (gradients_w[i] ** 2)\n",
        "        weights[i] -= lr * gradients_w[i] / (np.sqrt(cache_w[i]) + epsilon)\n",
        "        cache_b[i] = beta * cache_b[i] + (1 - beta) * (gradients_b[i] ** 2)\n",
        "        biases[i] -= lr * gradients_b[i] / (np.sqrt(cache_b[i]) + epsilon)\n",
        "    return weights, biases, cache_w, cache_b\n"
      ],
      "metadata": {
        "id": "OCUlDUFec0eX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the best model parameters\n",
        "best_config = {\n",
        "    'hidden_layers': 3,\n",
        "    'hidden_size': 64,\n",
        "    'activation': 'sigmoid',\n",
        "    'weight_init': 'xavier',\n",
        "    'optimizer': 'rmsprop',\n",
        "    'batch_size': 16,\n",
        "    'epochs': 10,\n",
        "    'learning_rate': 0.001,\n",
        "    'weight_decay': 0\n",
        "}"
      ],
      "metadata": {
        "id": "bfipkzg-c0hn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Wandb\n",
        "wandb.init(project=\"fashion-mnist\", config=best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "PBSN-J8Wc0kX",
        "outputId": "fbcf2229-40a6-4596-afba-ef4ef85233a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmangleshpatidar2233\u001b[0m (\u001b[33mmangleshpatidar2233-iit-madras-alumni-association\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_104241-pw7pat1o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o' target=\"_blank\">sunny-moon-478</a></strong> to <a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist' target=\"_blank\">https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o' target=\"_blank\">https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a7ee9718190>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(X_train, y_train, X_val, y_val, config):\n",
        "    np.random.seed(42)\n",
        "    layers = [X_train.shape[1]] + [config['hidden_size']] * config['hidden_layers'] + [10]\n",
        "    activation = [config['activation']] * config['hidden_layers'] + ['sigmoid']\n",
        "\n",
        "    weights, biases = initialize_weights(layers, config['weight_init'])\n",
        "    cache_w = [np.zeros_like(w) for w in weights]\n",
        "    cache_b = [np.zeros_like(b) for b in biases]\n",
        "\n",
        "    batch_size = config['batch_size']\n",
        "    epochs = config['epochs']\n",
        "    lr = config['learning_rate']\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(X_train.shape[0])\n",
        "        X_train_shuffled, y_train_shuffled = X_train[indices], y_train[indices]\n",
        "\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for i in range(0, X_train_shuffled.shape[0], batch_size):\n",
        "            X_batch = X_train_shuffled[i:i+batch_size]\n",
        "            y_batch = y_train_shuffled[i:i+batch_size]\n",
        "\n",
        "            # Forward propagation\n",
        "            activations = forward_propagation(X_batch, weights, biases, activation)\n",
        "\n",
        "            # Calculate training loss (cross-entropy loss)\n",
        "            output = activations[-1]\n",
        "            train_loss += -np.sum(y_batch * np.log(output + 1e-8)) / len(y_batch)\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            train_preds = np.argmax(output, axis=1)\n",
        "            train_true = np.argmax(y_batch, axis=1)\n",
        "            train_correct += np.sum(train_preds == train_true)\n",
        "            train_total += len(y_batch)\n",
        "\n",
        "            # Backpropagation\n",
        "            gradients_w, gradients_b = backpropagation(y_batch, activations, weights)\n",
        "            weights, biases, cache_w, cache_b = rmsprop(weights, biases, gradients_w, gradients_b, lr, cache_w, cache_b)\n",
        "\n",
        "        # Calculate average training loss and accuracy for the epoch\n",
        "        train_loss /= (X_train_shuffled.shape[0] // batch_size)\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        # Log training metrics to Wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_accuracy\n",
        "        })\n",
        "\n",
        "        # Print training metrics\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    return weights, biases"
      ],
      "metadata": {
        "id": "ckpMRuGac0m2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the best model split  train and val\n",
        "X_train, X_val = X_train[:54000], X_train[54000:]\n",
        "y_train, y_val = y_train[:54000], y_train[54000:]\n",
        "weights, biases = train_network(X_train, y_train, X_val, y_val, best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAaxKxTsc0ph",
        "outputId": "f1b8b874-b39e-4feb-a503-6d76421b75c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.7517, Train Accuracy: 0.7261\n",
            "Epoch 2/10, Train Loss: 0.4868, Train Accuracy: 0.8454\n",
            "Epoch 3/10, Train Loss: 0.4351, Train Accuracy: 0.8616\n",
            "Epoch 4/10, Train Loss: 0.4039, Train Accuracy: 0.8708\n",
            "Epoch 5/10, Train Loss: 0.3847, Train Accuracy: 0.8769\n",
            "Epoch 6/10, Train Loss: 0.3670, Train Accuracy: 0.8835\n",
            "Epoch 7/10, Train Loss: 0.3555, Train Accuracy: 0.8876\n",
            "Epoch 8/10, Train Loss: 0.3458, Train Accuracy: 0.8919\n",
            "Epoch 9/10, Train Loss: 0.3377, Train Accuracy: 0.8944\n",
            "Epoch 10/10, Train Loss: 0.3306, Train Accuracy: 0.8967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "activations = forward_propagation(X_test, weights, biases, [best_config['activation']] * best_config['hidden_layers'] + ['sigmoid'])\n",
        "test_predictions = np.argmax(activations[-1], axis=1)\n",
        "\n",
        "# One-hot encode y_test_original for loss calculation\n",
        "y_test_one_hot = np.eye(10)[y_test_original]\n",
        "\n",
        "# Calculate test loss (cross-entropy loss)\n",
        "test_loss = -np.sum(y_test_one_hot * np.log(activations[-1] + 1e-8)) / len(y_test_original)"
      ],
      "metadata": {
        "id": "q014wlBZc0sV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate test accuracy\n",
        "test_accuracy = np.mean(test_predictions == y_test_original)\n",
        "\n",
        "# Log test metrics to Wandb\n",
        "wandb.log({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_accuracy\": test_accuracy\n",
        "})"
      ],
      "metadata": {
        "id": "R4IrxQfOe7MN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print test metrics\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4flRhE0Je3-v",
        "outputId": "f7e267dd-f39e-4f26-edc0-973937bc264c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3908, Test Accuracy: 0.8718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "W49w5EUnckdY",
        "outputId": "417e44b1-160f-4950-98d5-d694563b47be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.8718</td></tr><tr><td>test_loss</td><td>0.39076</td></tr><tr><td>train_accuracy</td><td>0.89669</td></tr><tr><td>train_loss</td><td>0.33064</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sunny-moon-478</strong> at: <a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o' target=\"_blank\">https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist/runs/pw7pat1o</a><br> View project at: <a href='https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist' target=\"_blank\">https://wandb.ai/mangleshpatidar2233-iit-madras-alumni-association/fashion-mnist</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_104241-pw7pat1o/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test_original, test_predictions)\n",
        "\n",
        "# Plot confusion matrix\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix for Fashion-MNIST Test Set', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=14)\n",
        "plt.ylabel('True Labels', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "# Save the confusion matrix plot to a file\n",
        "confusion_matrix_path = \"confusion_matrix.png\"\n",
        "plt.savefig(confusion_matrix_path)\n",
        "plt.close()\n",
        "\n",
        "# Log the confusion matrix as an image to Wandb\n",
        "wandb.log({\"confusion_matrix\": wandb.Image(confusion_matrix_path)})\n",
        "\n",
        "# Finish Wandb run\n",
        "wandb.finish()\n"
      ]
    }
  ]
}